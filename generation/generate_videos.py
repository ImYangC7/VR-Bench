#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„è§†é¢‘ç”Ÿæˆå·¥å…·
ä½¿ç”¨GameAdapterç»Ÿä¸€æ¥å£ç”Ÿæˆæ‰€æœ‰æ¸¸æˆçš„è§†é¢‘
"""
import sys
import logging
from pathlib import Path
from multiprocessing import Pool, cpu_count
from typing import Optional

sys.path.insert(0, str(Path(__file__).parent.parent))

from core.schema import UnifiedState
from core.game_adapter import GameAdapter

logging.basicConfig(level=logging.INFO, format='%(message)s')


def get_game_adapter(game_type: str) -> GameAdapter:
    """æ ¹æ®æ¸¸æˆç±»å‹è·å–å¯¹åº”çš„é€‚é…å™¨"""
    if game_type == "sokoban":
        from games.sokoban.adapter import SokobanAdapter
        return SokobanAdapter()
    elif game_type == "maze":
        from games.maze.adapter import MazeAdapter
        return MazeAdapter()
    elif game_type == "pathfinder":
        from games.pathfinder.adapter import PathFinderAdapter
        return PathFinderAdapter()
    elif game_type == "trapfield":
        from games.trapfield.adapter import TrapFieldAdapter
        return TrapFieldAdapter()
    elif game_type == "maze3d":
        from games.maze3d.adapter import Maze3DAdapter
        return Maze3DAdapter()
    else:
        raise ValueError(f"Unknown game type: {game_type}")


def extract_first_frame(video_path: str, image_path: str) -> bool:
    """ä»è§†é¢‘æå–ç¬¬ä¸€å¸§"""
    try:
        import imageio.v2 as imageio
        reader = imageio.get_reader(video_path)
        first_frame = reader.get_data(0)
        reader.close()
        imageio.imwrite(image_path, first_frame)
        return True
    except Exception as e:
        logging.warning(f"Failed to extract first frame: {e}")
        return False


def process_single_path(args):
    """å¤„ç†å•æ¡è·¯å¾„ï¼ˆç”Ÿæˆä¸€ä¸ªè§†é¢‘ï¼‰"""
    state_path, game_type, path_id, video_path, skip_existing, assets_folder = args

    try:
        if skip_existing and Path(video_path).exists():
            return (path_id, 'skipped', None)

        # ä½¿ç”¨adapterçš„ç»Ÿä¸€æ¥å£
        adapter = get_game_adapter(game_type)
        success = adapter.generate_video(
            str(state_path),
            str(video_path),
            assets_folder=assets_folder
        )

        if success and Path(video_path).exists():
            return (path_id, 'success', None)
        else:
            return (path_id, 'failed', 'è§†é¢‘ç”Ÿæˆå¤±è´¥')

    except Exception as e:
        return (path_id, 'failed', str(e))


def process_single_state(
    state_path: Path,
    game_type: str,
    skip_existing: bool = False,
    verbose: bool = True,
    num_workers: int = 4,
    assets_folder: Optional[str] = None
) -> dict:
    """å¤„ç†å•ä¸ªstateæ–‡ä»¶ï¼Œç”Ÿæˆæ‰€æœ‰æœ€ä¼˜è·¯å¾„çš„è§†é¢‘"""
    from generation.path_finder import find_optimal_paths
    
    stats = {'total_paths': 0, 'success': 0, 'failed': 0, 'skipped': 0}

    try:
        state = UnifiedState.load(str(state_path))
        paths = find_optimal_paths(state, game_type)

        if game_type == 'pathfinder':
            paths = [p[0] for p in paths]

        stats['total_paths'] = len(paths)

        if not paths:
            if verbose:
                logging.warning(f"âš ï¸  {state_path.name}: æœªæ‰¾åˆ°è·¯å¾„")
            return stats

        state_dir = state_path.parent
        videos_dir = state_dir.parent / 'videos'
        images_dir = state_dir.parent / 'images'
        videos_dir.mkdir(parents=True, exist_ok=True)
        images_dir.mkdir(parents=True, exist_ok=True)

        base_name = state_path.stem
        
        # ä¸ºæ¯æ¡è·¯å¾„ç”Ÿæˆä»»åŠ¡ï¼ˆä»…ç¬¬ä¸€æ¡è·¯å¾„ï¼Œå› ä¸ºadapterä¼šè‡ªåŠ¨æŸ¥æ‰¾æœ€ä¼˜è·¯å¾„ï¼‰
        # å¯¹äºå¤šæ¡è·¯å¾„çš„æƒ…å†µï¼Œå¯ä»¥æ‰©å±•adapteræ¥å£æ”¯æŒæŒ‡å®šè·¯å¾„
        tasks = [(state_path, game_type, 0, str(videos_dir / f"{base_name}_0.mp4"), skip_existing, assets_folder)]

        with Pool(processes=min(num_workers, len(tasks))) as pool:
            results = pool.map(process_single_path, tasks)

        first_video = videos_dir / f"{base_name}_0.mp4"
        if first_video.exists():
            extract_first_frame(str(first_video), str(images_dir / f"{base_name}.png"))

        for path_id, status, error_msg in results:
            if status == 'success':
                stats['success'] += 1
            elif status == 'skipped':
                stats['skipped'] += 1
            else:
                stats['failed'] += 1
                if verbose:
                    logging.error(f"  âŒ {base_name}_{path_id}: {error_msg}")

    except Exception as e:
        if verbose:
            logging.error(f"âŒ {state_path.name}: {e}")

    return stats


def batch_process_dataset(
    dataset_root: str,
    skip_existing: bool = False,
    verbose: bool = True,
    num_workers: int = None,
    parallel_states: int = 1,
    assets_folder: Optional[str] = None
):
    """æ‰¹é‡å¤„ç†datasetç›®å½•"""
    from functools import partial
    
    if num_workers is None:
        num_workers = max(1, cpu_count() // 2)

    dataset_path = Path(dataset_root)
    state_files = []

    for state_file in dataset_path.rglob('states/*.json'):
        path_str = str(state_file).lower()
        if 'pathfinder' in path_str or 'irregular_maze' in path_str:
            game_type = 'pathfinder'
        elif '3d' in path_str or 'maze3d' in path_str:
            game_type = 'maze3d'
        elif 'maze' in path_str:
            game_type = 'maze'
        elif 'trapfield' in path_str:
            game_type = 'trapfield'
        elif 'sokoban' in path_str:
            game_type = 'sokoban'
        else:
            continue
        state_files.append((state_file, game_type))

    logging.info(f"æ‰¾åˆ° {len(state_files)} ä¸ªstateæ–‡ä»¶")
    logging.info(f"å¹¶è¡Œ: {parallel_states} states, æ¯ä¸ª{num_workers} workers")
    if assets_folder:
        logging.info(f"çš®è‚¤: {assets_folder}\n")
    else:
        logging.info(f"çš®è‚¤: é»˜è®¤\n")

    by_game = {}
    for state_file, game_type in state_files:
        by_game.setdefault(game_type, []).append(state_file)

    total_stats = {'total_states': 0, 'total_paths': 0, 'success': 0, 'failed': 0, 'skipped': 0}

    for game_type in sorted(by_game.keys()):
        state_paths = by_game[game_type]
        logging.info(f"\n{'='*60}")
        logging.info(f"{game_type.upper()}: {len(state_paths)} files")
        logging.info(f"{'='*60}\n")

        if parallel_states > 1:
            process_func = partial(
                process_single_state,
                game_type=game_type,
                skip_existing=skip_existing,
                verbose=False,
                num_workers=num_workers,
                assets_folder=assets_folder
            )
            with Pool(processes=parallel_states) as pool:
                results = pool.map(process_func, sorted(state_paths))

            for i, stats in enumerate(results):
                for k in total_stats:
                    total_stats[k] += stats.get(k.replace('total_states', 'total_paths') if k == 'total_states' else k, 0)
                total_stats['total_states'] += 1
                if verbose:
                    s = stats
                    logging.info(f"âœ… {sorted(state_paths)[i].name}: {s['total_paths']}è·¯å¾„ "
                               f"{s['success']}æˆåŠŸ {s['skipped']}è·³è¿‡ {s['failed']}å¤±è´¥")
        else:
            for state_path in sorted(state_paths):
                if verbose:
                    logging.info(f"ğŸ“„ {state_path.relative_to(dataset_path)}")
                stats = process_single_state(state_path, game_type, skip_existing, verbose, num_workers, assets_folder)
                total_stats['total_states'] += 1
                for k in ['total_paths', 'success', 'failed', 'skipped']:
                    total_stats[k] += stats[k]

    logging.info(f"\n{'='*60}")
    logging.info("å®Œæˆ")
    logging.info(f"{'='*60}")
    logging.info(f"States: {total_stats['total_states']}, Paths: {total_stats['total_paths']}")
    logging.info(f"æˆåŠŸ: {total_stats['success']}, è·³è¿‡: {total_stats['skipped']}, å¤±è´¥: {total_stats['failed']}")
    logging.info(f"{'='*60}\n")


def main():
    import argparse
    parser = argparse.ArgumentParser(description='æ‰¹é‡ç”ŸæˆGTè§†é¢‘')
    parser.add_argument('dataset', help='Datasetæ ¹ç›®å½•')
    parser.add_argument('--skip-existing', action='store_true', help='è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶')
    parser.add_argument('--quiet', action='store_true', help='é™é»˜æ¨¡å¼')
    parser.add_argument('--workers', type=int, default=None,
                       help=f'æ¯ä¸ªstateçš„workers (é»˜è®¤: {max(1, cpu_count()//2)})')
    parser.add_argument('--parallel-states', type=int, default=1, help='å¹¶è¡Œå¤„ç†çš„statesæ•°')
    parser.add_argument('--skin', type=str, default=None,
                       help='çš®è‚¤æ–‡ä»¶å¤¹è·¯å¾„ (ä¾‹å¦‚: skins/maze/5)')
    args = parser.parse_args()

    batch_process_dataset(
        args.dataset,
        args.skip_existing,
        not args.quiet,
        args.workers,
        args.parallel_states,
        args.skin
    )


if __name__ == '__main__':
    main()
